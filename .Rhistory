# easy load
merged.table <- readRDS("merged_table.rds")
pheatmap(t(merged.table), cluster_rows = FALSE, scale = "row")
####################
# Long operation!
####################
# Divide the subtraining set into 19 log(price) quantiles + 1 "free" item bin
# Totally 19 segments
percentiles <- seq(0.05, 0.99, 0.05)
merged.table <- parse_text(mini.subtrain$name[mini.subtrain$price == 0])[,c(1,3)]
colnames(merged.table)[2] <- paste0("price_percentile_0")
merged.table <- rbind(head(merged.table,10),tail(merged.table,10))
mini.subtrain.nonzero <- mini.subtrain[mini.subtrain$price != 0,]
for(i in seq_along(percentiles)){
# Perform text frequency mining within the first segment and hold the results
text <- mini.subtrain.nonzero$name[log(mini.subtrain.nonzero$price) >= quantile(log(mini.subtrain.nonzero$price),percentiles[i])]
sorted.table <- parse_text(text)
sorted.table <- sorted.table[,c(1,3)]
colnames(sorted.table)[2] <- paste0("price_percentile_%",percentiles[i]*100)
sorted.table <- rbind(head(sorted.table,10),tail(sorted.table,10))
merged.table <- merge(merged.table,sorted.table, by = "Word", all = TRUE)
# continue until all price segments are finished
}
merged.table <- merged.table[!is.na(merged.table$Word),]
merged.table <- unique.data.frame(merged.table)
row.names(merged.table) = merged.table$Word
merged.table <- dplyr::select(merged.table, -Word)
merged.table <- as.matrix(merged.table)
#Replace NA's with zero
for (i in 1:20){merged.table[is.na(merged.table[,i]),i] <- 0}
#Save for future use
saveRDS(merged.table,"merged_table.rds")
# easy load
merged.table <- readRDS("merged_table.rds")
pheatmap(t(merged.table), cluster_rows = FALSE, scale = "row")
pink.test <- word.feature.engineer.binary(mini.subtrain$name,"pink")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(pink.test)))+
geom_boxplot(fill = c("navy","red"))
size.test <- word.feature.engineer.binary(mini.subtrain$name,"pink")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(size.test)))+
geom_boxplot(fill = c("navy","red"))
jordan.test <- word.feature.engineer.binary(mini.subtrain$name,"jordan")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(jordan.test)))+
geom_boxplot(fill = c("navy","red"))
size.test <- word.feature.engineer.binary(mini.subtrain$name,"size")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(size.test)))+
geom_boxplot(fill = c("navy","red"))
shirt.test <- word.feature.engineer.binary(mini.subtrain$name,"shirt")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(shirt.test)))+
geom_boxplot(fill = c("navy","red"))
michael.test <- word.feature.engineer.binary(mini.subtrain$name,"michael")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(michael.test)))+
geom_boxplot(fill = c("navy","red"))
cor(michael.test,michael.brand)
cor(michael.test,mini.subtrain$michael.brand)
iphon.test <- word.feature.engineer.binary(mini.subtrain$name,"iphon")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(iphon.test)))+
geom_boxplot(fill = c("navy","red"))
table(iphon.test)
table(jordan.test)
bundl.test <- word.feature.engineer.binary(mini.subtrain$name,"bundl")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(bundl.test)))+
geom_boxplot(fill = c("navy","red"))
table(bundl.test)
# Long operation!
mini.subtrain$jordan.name <- word.feature.engineer.binary(mini.subtrain$name,"jordan")
subtrain$jordan.name <- word.feature.engineer.binary(subtrain$name,"jordan")
validation$jordan.name <- word.feature.engineer.binary(validation$name,"jordan")
test$jordan.name <- word.feature.engineer.binary(test$brand,"jordan")
mini.subtrain$iphon.name <- word.feature.engineer.binary(mini.subtrain$name,"iphon")
subtrain$iphon.name <- word.feature.engineer.binary(subtrain$name,"iphon")
validation$iphon.name <- word.feature.engineer.binary(validation$name,"iphon")
test$iphon.name <- word.feature.engineer.binary(test$brand,"iphon")
mini.subtrain$bundl.name <- word.feature.engineer.binary(mini.subtrain$name,"bundl")
subtrain$bundl.name <- word.feature.engineer.binary(subtrain$name,"bundl")
validation$bundl.name <- word.feature.engineer.binary(validation$name,"bundl")
test$bundl.name <- word.feature.engineer.binary(test$brand,"bundl")
#At this point it is necessary to save engineered data sets again for future easy loading:
saveRDS(mini.subtrain,"mini_subtrain.rds")
saveRDS(subtrain,"subtrain.rds")
saveRDS(validation,"validation.rds")
saveRDS(test,"test.rds")
placeholder.test <- word.feature.engineer.binary(mini.subtrain$name,"\\[rm]")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(placeholder.test)))+
geom_boxplot(fill = c("navy","red"))
placeholder.test <- word.feature.engineer.binary(mini.subtrain$item_description,"\\[rm]")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(placeholder.test)))+
geom_boxplot(fill = c("navy","red"))
placeholder.test <- word.feature.engineer(mini.subtrain$name,"\\[rm]")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(placeholder.test)))+
geom_boxplot(fill = c("navy","red"))
placeholder.test <- word.feature.engineer(mini.subtrain$name,"\\[rm]")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(placeholder.test)))+
geom_boxplot(fill = c("navy","red","lightgreen"))
capital.letter.counter <- function(text.vector){
# Return the occurance of capital letters in the given text vector
capital.letter.count <- sapply(text.vector,function(x){
return(nchar(grep("[A-Z]",x)))})
}
capital.letter.test <- capital.letter.counter(mini.subtrain$item_description)
capital.letter.test[1:5]
text.vector = mini.subtrain$item_description[1]
x = text.vector
grep("[A-Z]",x)
x
grepRaw("[A-Z]",x)
grep("[A-Z]",x, value = T)
str_extract(x,"[A-Z]")
str_extract(x,"*[A-Z]")
str_extract(x,"[*A-Z]")
str_extract_all(x,"[A-Z]")
unlist(str_extract_all(x,"[A-Z]"))
length(unlist(str_extract_all(x,"[A-Z]")))
capital.letter.counter <- function(text.vector){
# Return the occurance of capital letters in the given text vector
capital.letter.count <- sapply(text.vector,function(x){
return(length(unlist(str_extract_all(x,"[A-Z]"))))})
}
capital.letter.test <- capital.letter.counter(mini.subtrain$item_description)
plot(y =log(mini.subtrain$price) x = capital.letter.test,pch = 19, col = "navy", cex = 0.2)
plot(y =log(mini.subtrain$price), x = capital.letter.test,pch = 19, col = "navy", cex = 0.2)
plot(y =log(mini.subtrain$price), x = log(capital.letter.test),pch = 19, col = "navy", cex = 0.2)
capital.letter.test <- capital.letter.counter(mini.subtrain$name)
plot(y =log(mini.subtrain$price), x = log(capital.letter.test),pch = 19, col = "navy", cex = 0.2)
capital.letter.test <- capital.letter.counter(mini.subtrain$brand_name)
plot(y =log(mini.subtrain$price), x = log(capital.letter.test),pch = 19, col = "navy", cex = 0.2)
capital.letter.test <- capital.letter.counter(mini.subtrain$category_name)
plot(y =log(mini.subtrain$price), x = log(capital.letter.test),pch = 19, col = "navy", cex = 0.2)
capital.letter.test <- capital.letter.counter(mini.subtrain$brand_name)
plot(y =log(mini.subtrain$price), x = log(capital.letter.test),pch = 19, col = "navy", cex = 0.2)
# Long operation!
mini.subtrain$cap.letter.brand <- capital.letter.counter(mini.subtrain$brand_name)
subtrain$cap.letter.brand <- capital.letter.counter(subtrain$brand_name)
validation$cap.letter.brand <- capital.letter.counter(valiadtion$brand_name)
validation$cap.letter.brand <- capital.letter.counter(validation$brand_name)
test$cap.letter.brand <- capital.letter.counter(test$brand_name)
#At this point it is necessary to save engineered data sets again for future easy loading:
saveRDS(mini.subtrain,"mini_subtrain.rds")
saveRDS(subtrain,"subtrain.rds")
saveRDS(validation,"validation.rds")
saveRDS(test,"test.rds")
mini.subtrain <-dplyr::select(mini.subtrain, -name, -item_description,-category_name, -brand_name)
subtrain <-dplyr::select(subtrain, -name, -item_description,-category_name, -brand_name)
validation <-dplyr::select(validation, -name, -item_description,-category_name, -brand_name)
test <-dplyr::select(test, -name, -item_description,-category_name, -brand_name)
library(corrplot)
corrplot(cor(mini.subtrain), method = c("shade"), bg = "gray", addgrid.col = "gray")
#At this point it is necessary to save engineered data sets again for future easy loading:
saveRDS(mini.subtrain,"mini_subtrain_locked.rds")
saveRDS(subtrain,"subtrain_locked.rds")
saveRDS(validation,"validation_locked.rds")
saveRDS(test,"test_locked.rds")
# Find the 10 most frequent terms: term_count
term_count <- freq_terms(new_text,4)
library(qdap)
# Print new_text to the console
new_text <- "Text mining usually involves the process of structuring the input text. The overarching goal is, essentially, to turn text into data for analysis, via application of natural language processing (NLP) and analytical methods."
# Find the 10 most frequent terms: term_count
term_count <- freq_terms(new_text,4)
# Plot term_count
plot(term_count)
tweets <- read.csv("https://assets.datacamp.com/production/course_935/datasets/coffee.csv", stringsAsFactors = FALSE)
str(tweets)
View(tweets)
nrow(tweets)
# Isolate text from tweets: coffee_tweets
coffee_tweets <- tweets$text
# Load tm
library(tm)
# Make a vector source: coffee_source
coffee_source <- VectorSource(coffee_tweets)
## coffee_source is already in your workspace
# Make a volatile corpus: coffee_corpus
coffee_corpus <- VCorpus(coffee_source)
# Print out coffee_corpus
coffee_corpus
# Print data on the 15th tweet in coffee_corpus
coffee_corpus[[15]]
# Print the content of the 15th tweet in coffee_corpus
coffee_corpus[[15]][1]
# Create the object: text
text <- "<b>She</b> woke up at       6 A.M. It\'s so early!  She was only 10% awake and began drinking coffee in front of her computer."
# All lowercase
tolower(text)
# Remove punctuation
removePunctuation(text)
# Remove numbers
removeNumbers(text)
# Remove whitespace
stripWhitespace(text)
stemDocument(c("computational", "computers", "computation"))
# Create complicate
complicate <- c("complicated", "complication","complicatedly" )
# Perform word stemming: stem_doc
stem_doc <- stemDocument(complicate)
# Create the completion dictionary: comp_dict
comp_dict <- "complicate"
# Perform stem completion: complete_text
complete_text <- stemCompletion(stem_doc,comp_dict)
# Print complete_text
print(complete_text)
shiny::runApp('Desktop/2016/Data_science/companion')
events.list <- unique(fromJSON(paste0('https://api.fda.gov/drug/event.json?search=receivedate:[',start.date,'+TO+',end.date,']+AND+patient.drug.openfda.brand_name.exact:(%22',drug,'%22)&count=patient.reaction.reactionmeddrapt.exact'))$results$term)
message(        events.list <- unique(fromJSON(paste0('https://api.fda.gov/drug/event.json?search=receivedate:[',start.date,'+TO+',end.date,']+AND+patient.drug.openfda.brand_name.exact:(%22',drug,'%22)&count=patient.reaction.reactionmeddrapt.exact'))$results$term)
)
drug.list
PMA.data <- get.state.PMA()
us <- map_data("state") # convert state spatial data into a ggplot map_data
# note that this contains 49 states, the matching data above has to be filtered to present only these 49 states (therefore the filtering: statename %in% levels(factor(us$region))))
gg <- ggplot() # make an empty plot
# first add the us map_data as the plain U.S. map frame
template <- gg + geom_map(data = us,map = us, aes(x = long, y = lat,
map_id = region ),fill = "#ffffff", color = "#ffffff", size = 0.15)
A <- template + geom_map (data = PMA.data, map = us,
aes(fill = count, map_id = state.name),
color="#ffffff", size = 0.3) +
scale_fill_continuous(low='thistle2', high='darkred',
guide='colorbar', name = "Number of\nfatalities")
library(RColorBrewer)
library(shiny)
library(plotly)
library(colorspace)
library(dplyr)
library(ape)
library(googleVis)
library(lubridate)
library(shinydashboard)
library(stringr)
require(jsonlite)
library(maps)
##############################################################################
# get.state.510k: gets state counts for all 510k submissions received to date
##############################################################################
get.state.510k <- function(x){
is.this.error <- try(query.510k.state <- fromJSON("https://api.fda.gov/device/510k.json?count=state")$results)
if((is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 400.\n')&(is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 404.\n')){
query.510k.state$term <- toupper(query.510k.state$term)
query.510k.state <- merge(query.510k.state,state.frame, by.x = "term", by.y = "state.abb", all = FALSE)
query.510k.state$state.name <- tolower(query.510k.state$state.name)
return(query.510k.state)
}else{
query.510k.state <- NULL
return(query.510k.state)
}
}
##############################################################################
# get.state.PMA: gets state counts for all PMA submissions received to date
##############################################################################
get.state.PMA <- function(x){
is.this.error <- try(query.PMA.state <- fromJSON("https://api.fda.gov/device/PMA.json?count=state")$results)
if((is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 400.\n')&(is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 404.\n')){
query.PMA.state$term <- toupper(query.PMA.state$term)
query.PMA.state <- merge(query.PMA.state,state.frame, by.x = "term", by.y = "state.abb", all = FALSE)
query.PMA.state$state.name <- tolower(query.PMA.state$state.name)
return(query.PMA.state)
}else{
query.PMA.state <- NULL
return(query.PMA.state)
}
}
##############################################################################
# get.state.PMA.companion: gets state counts for all PMA submissions for companion Dx received to date
##############################################################################
get.state.PMA.companion <- function(x){
is.this.error <- try(query.PMA.state <- fromJSON("https://api.fda.gov/device/PMA.json?count=state")$results)
if((is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 400.\n')&(is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 404.\n')){
query.PMA.state$term <- toupper(query.PMA.state$term)
query.PMA.state <- merge(query.PMA.state,state.frame, by.x = "term", by.y = "state.abb", all = FALSE)
query.PMA.state$state.name <- tolower(query.PMA.state$state.name)
return(query.PMA.state)
}else{
query.PMA.state <- NULL
return(query.PMA.state)
}
}
PMA.data <- get.state.PMA()
us <- map_data("state") # convert state spatial data into a ggplot map_data
# note that this contains 49 states, the matching data above has to be filtered to present only these 49 states (therefore the filtering: statename %in% levels(factor(us$region))))
gg <- ggplot() # make an empty plot
# first add the us map_data as the plain U.S. map frame
template <- gg + geom_map(data = us,map = us, aes(x = long, y = lat,
map_id = region ),fill = "#ffffff", color = "#ffffff", size = 0.15)
A <- template + geom_map (data = PMA.data, map = us,
aes(fill = count, map_id = state.name),
color="#ffffff", size = 0.3) +
scale_fill_continuous(low='thistle2', high='darkred',
guide='colorbar', name = "Number of\nfatalities")
PMA.data <- get.state.PMA()
us <- map_data("state") # convert state spatial data into a ggplot map_data
# note that this contains 49 states, the matching data above has to be filtered to present only these 49 states (therefore the filtering: statename %in% levels(factor(us$region))))
gg <- ggplot() # make an empty plot
# first add the us map_data as the plain U.S. map frame
template <- gg + geom_map(data = us,map = us, aes(x = long, y = lat,
map_id = region ),fill = "#ffffff", color = "#ffffff", size = 0.15)
A <- template + geom_map (data = PMA.data, map = us,
aes(fill = count, map_id = state.name),
color="#ffffff", size = 0.3) +
scale_fill_continuous(low='thistle2', high='darkred',
guide='colorbar', name = "Number of\nfatalities")
PMA.data <- get.state.PMA()
state.frame <- data.frame(state.abb,state.name)
PMA.data <- get.state.PMA()
us <- map_data("state") # convert state spatial data into a ggplot map_data
# note that this contains 49 states, the matching data above has to be filtered to present only these 49 states (therefore the filtering: statename %in% levels(factor(us$region))))
gg <- ggplot() # make an empty plot
# first add the us map_data as the plain U.S. map frame
template <- gg + geom_map(data = us,map = us, aes(x = long, y = lat,
map_id = region ),fill = "#ffffff", color = "#ffffff", size = 0.15)
A <- template + geom_map (data = PMA.data, map = us,
aes(fill = count, map_id = state.name),
color="#ffffff", size = 0.3) +
scale_fill_continuous(low='thistle2', high='darkred',
guide='colorbar', name = "Number of\nfatalities")
print(A)
PMA.data <- get.state.PMA()
us <- map_data("state") # convert state spatial data into a ggplot map_data
# note that this contains 49 states, the matching data above has to be filtered to present only these 49 states (therefore the filtering: statename %in% levels(factor(us$region))))
gg <- ggplot() # make an empty plot
# first add the us map_data as the plain U.S. map frame
template <- gg + geom_map(data = us,map = us, aes(x = long, y = lat,
map_id = region ),fill = "#ffffff", color = "#ffffff", size = 0.15)
A <- template + geom_map (data = PMA.data, map = us,
aes(fill = count, map_id = state.name),
color="#ffffff", size = 0.3) +
scale_fill_continuous(low='thistle2', high='darkred',
guide='colorbar', name = "Number of\nfatalities")
A <- A + labs(x=NULL, y=NULL,
title = "(A) Distribution of fatalities caused by tornadoes
across the United States")+
coord_map("albers", lat0 = 39, lat1 = 45)+
theme(panel.border = element_blank())+
theme(panel.background = element_blank())+
theme(axis.ticks = element_blank())+
theme(axis.text = element_blank())+
theme(title = element_text(face = "bold",size = 8))
print(A)
setwd("~/Desktop/2016/Data_science/companion")
dir()
PMA.numbers <- readRDS("drug.device.table.rds)
)
")"
))
PMA.numbers <- readRDS("drug.device.table.rds")
PMA.numbers <- readRDS("drug.device.table.rds")
PMA.numbers <- readRDS("drug.device.table.rds")$PMA
PMA.numbers <- tolower(readRDS("drug.device.table.rds")$PMA)
PMA.numbers
PMA.numbers <- sapply(tolower(readRDS("drug.device.table.rds")$PMA),substring,1,7)
PMA.numbers
PMA.numbers <- unname(sapply(tolower(readRDS("drug.device.table.rds")$PMA),substring,1,7))
PMA.numbers
i =1
is.this.error <- try(query.PMA.state <- fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=pma_number:',PMA.numbers[i],'?count=state'))$results)
PMA.numbers[i]
fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=pma_number:',PMA.numbers[i],'?count=state'))$results
fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=pma_number:p170019?count=state'))$results
fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=pma_number=p170019?count=state'))$results
fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=',PMA.numbers[i],'?count=state'))$results
fromJSON(paste0('https://api.fda.gov/device/PMA.json?search:',PMA.numbers[i],'?count=state'))$results
fromJSON(paste0('https://api.fda.gov/device/pma.json?search=p170019&count=state'))$results
fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=',PMA.numbers[i],'?count=state'))$results
PMA.numbers[i]
paste0('https://api.fda.gov/device/PMA.json?search=',PMA.numbers[i],'?count=state')
paste0('https://api.fda.gov/device/pma.json?search=p170019&count=state')
fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=',PMA.numbers[i],'&count=state'))$results
is.this.error <- try(query.PMA.state <- fromJSON(fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=',PMA.numbers[i],'&count=state')))$results)
is.this.error <- try(query.PMA.state <- fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=',PMA.numbers[i],'&count=state')))$results)
is.this.error <- try(query.PMA.state <- fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=',PMA.numbers[i],'&count=state'))$results)
View(query.PMA.state)
query.PMA.state$term <- toupper(query.PMA.state$term)
query.PMA.state <- merge(query.PMA.state,state.frame, by.x = "term", by.y = "state.abb", all = FALSE)
query.PMA.state$state.name <- tolower(query.PMA.state$state.name)
View(query.PMA.state)
query.PMA.state.companion <- data.frame(term = "",
count= "",
state.name = "", stringsAsFactors = FALSE)
query.PMA.state.companion <- rbind(query.PMA.state.companion,query.PMA.state)
View(query.PMA.state.companion)
PMA.numbers <- unname(sapply(tolower(readRDS("drug.device.table.rds")$PMA),substring,1,7))
query.PMA.state.companion <- data.frame(term = "",
count= "",
state.name = "", stringsAsFactors = FALSE)
for(i in 1:seq_along(PMA.numbers)){
is.this.error <- try(query.PMA.state <- fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=',PMA.numbers[i],'&count=state'))$results)
if((is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 400.\n')&(is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 404.\n')){
query.PMA.state$term <- toupper(query.PMA.state$term)
query.PMA.state <- merge(query.PMA.state,state.frame, by.x = "term", by.y = "state.abb", all = FALSE)
query.PMA.state$state.name <- tolower(query.PMA.state$state.name)
query.PMA.state.companion <- rbind(query.PMA.state.companion,query.PMA.state)
}
}
View(query.PMA.state.companion)
1:seq_along(PMA.numbers)
1:seq_along(PMA.numbers)
# Get PMA numbers from our cleaned list:
PMA.numbers <- unname(sapply(tolower(readRDS("drug.device.table.rds")$PMA),substring,1,7))
query.PMA.state.companion <- data.frame(term = "",
count= "",
state.name = "", stringsAsFactors = FALSE)
for(i in seq_along(PMA.numbers)){
is.this.error <- try(query.PMA.state <- fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=',PMA.numbers[i],'&count=state'))$results)
if((is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 400.\n')&(is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 404.\n')){
query.PMA.state$term <- toupper(query.PMA.state$term)
query.PMA.state <- merge(query.PMA.state,state.frame, by.x = "term", by.y = "state.abb", all = FALSE)
query.PMA.state$state.name <- tolower(query.PMA.state$state.name)
query.PMA.state.companion <- rbind(query.PMA.state.companion,query.PMA.state)
}
}
View(query.PMA.state.companion)
query.PMA.state.companion <- query.PMA.state.companion[-1,]
query.PMA.state.companion.summary <-  query.PMA.state.companion %>% group_by(state.name) %>% summarise(count = sum(count))
PMA.numbers <- unname(sapply(tolower(readRDS("drug.device.table.rds")$PMA),substring,1,7))
query.PMA.state.companion <- data.frame(term = 1,
count= "",
state.name = "", stringsAsFactors = FALSE)
for(i in seq_along(PMA.numbers)){
is.this.error <- try(query.PMA.state <- fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=',PMA.numbers[i],'&count=state'))$results)
if((is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 400.\n')&(is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 404.\n')){
query.PMA.state$term <- toupper(query.PMA.state$term)
query.PMA.state <- merge(query.PMA.state,state.frame, by.x = "term", by.y = "state.abb", all = FALSE)
query.PMA.state$state.name <- tolower(query.PMA.state$state.name)
query.PMA.state.companion <- rbind(query.PMA.state.companion,query.PMA.state)
}
}
query.PMA.state.companion <- query.PMA.state.companion[-1,]
query.PMA.state.companion$term <- as.numeric(query.PMA.state.companion)
query.PMA.state.companion.summary <-  query.PMA.state.companion %>% group_by(state.name) %>% summarise(count = sum(count))
query.PMA.state.companion$term <- as.numeric(query.PMA.state.companion$term)
query.PMA.state.companion.summary <-  query.PMA.state.companion %>% group_by(state.name) %>% summarise(count = sum(count))
query.PMA.state.companion <- data.frame(term = "",
count= "",
state.name = "", stringsAsFactors = FALSE)
for(i in seq_along(PMA.numbers)){
is.this.error <- try(query.PMA.state <- fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=',PMA.numbers[i],'&count=state'))$results)
if((is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 400.\n')&(is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 404.\n')){
query.PMA.state$term <- toupper(query.PMA.state$term)
query.PMA.state <- merge(query.PMA.state,state.frame, by.x = "term", by.y = "state.abb", all = FALSE)
query.PMA.state$state.name <- tolower(query.PMA.state$state.name)
query.PMA.state.companion <- rbind(query.PMA.state.companion,query.PMA.state)
}
}
query.PMA.state.companion <- query.PMA.state.companion[-1,]
query.PMA.state.companion$count <- as.numeric(query.PMA.state.companion$count)
query.PMA.state.companion.summary <-  query.PMA.state.companion %>% group_by(state.name) %>% summarise(count = sum(count))
View(query.PMA.state.companion.summary)
View(query.PMA.state.companion.summary)
get.state.PMA.companion <- function(x){
require(dplyr)
# Get PMA numbers from our cleaned list:
PMA.numbers <- unname(sapply(tolower(readRDS("drug.device.table.rds")$PMA),substring,1,7))
query.PMA.state.companion <- data.frame(term = "",
count= "",
state.name = "", stringsAsFactors = FALSE)
for(i in seq_along(PMA.numbers)){
is.this.error <- try(query.PMA.state <- fromJSON(paste0('https://api.fda.gov/device/PMA.json?search=',PMA.numbers[i],'&count=state'))$results)
if((is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 400.\n')&(is.this.error != 'Error in open.connection(con, \"rb\") : HTTP error 404.\n')){
query.PMA.state$term <- toupper(query.PMA.state$term)
query.PMA.state <- merge(query.PMA.state,state.frame, by.x = "term", by.y = "state.abb", all = FALSE)
query.PMA.state$state.name <- tolower(query.PMA.state$state.name)
query.PMA.state.companion <- rbind(query.PMA.state.companion,query.PMA.state)
}
}
query.PMA.state.companion <- query.PMA.state.companion[-1,]
query.PMA.state.companion$count <- as.numeric(query.PMA.state.companion$count)
query.PMA.state.companion.summary <-  query.PMA.state.companion %>% group_by(state.name) %>% summarise(count = sum(count))
return(query.PMA.state.companion.summary)
}
PMA.data <- get.state.PMA.companion()
us <- map_data("state") # convert state spatial data into a ggplot map_data
# note that this contains 49 states, the matching data above has to be filtered to present only these 49 states (therefore the filtering: statename %in% levels(factor(us$region))))
gg <- ggplot() # make an empty plot
# first add the us map_data as the plain U.S. map frame
template <- gg + geom_map(data = us,map = us, aes(x = long, y = lat,
map_id = region ),fill = "#ffffff", color = "#ffffff", size = 0.15)
A <- template + geom_map (data = PMA.data, map = us,
aes(fill = count, map_id = state.name),
color="#ffffff", size = 0.3) +
scale_fill_continuous(low='thistle2', high='darkred',
guide='colorbar', name = "Number of\nfatalities")
# Polish the plot
A <- A + labs(x=NULL, y=NULL,
title = "(A) Distribution of fatalities caused by tornadoes
across the United States")+
coord_map("albers", lat0 = 39, lat1 = 45)+
theme(panel.border = element_blank())+
theme(panel.background = element_blank())+
theme(axis.ticks = element_blank())+
theme(axis.text = element_blank())+
theme(title = element_text(face = "bold",size = 8))
PMA.data <- get.state.PMA.companion()
us <- map_data("state") # convert state spatial data into a ggplot map_data
# note that this contains 49 states, the matching data above has to be filtered to present only these 49 states (therefore the filtering: statename %in% levels(factor(us$region))))
gg <- ggplot() # make an empty plot
# first add the us map_data as the plain U.S. map frame
template <- gg + geom_map(data = us,map = us, aes(x = long, y = lat,
map_id = region ),fill = "#ffffff", color = "#ffffff", size = 0.15)
A <- template + geom_map (data = PMA.data, map = us,
aes(fill = count, map_id = state.name),
color="#ffffff", size = 0.3) +
scale_fill_continuous(low='thistle2', high='darkred',
guide='colorbar', name = "Number of\nfatalities")
# Polish the plot
A <- A + labs(x=NULL, y=NULL,
title = "(A) Distribution of fatalities caused by tornadoes
across the United States")+
coord_map("albers", lat0 = 39, lat1 = 45)+
theme(panel.border = element_blank())+
theme(panel.background = element_blank())+
theme(axis.ticks = element_blank())+
theme(axis.text = element_blank())+
theme(title = element_text(face = "bold",size = 8))
print(A)

merged.table[is.na(merged.table[,2]),2] <- 0
library(pheatmap)
pheatmap(t(merged.table))
####################
# Long operation!
####################
# Divide the subtraining set into 19 log(price) quantiles + 1 "free" item bin
# Totally 19 segments
percentiles <- seq(0.05, 0.99, 0.05)
merged.table <- parse_text(mini.subtrain$brand_name[mini.subtrain$price == 0])[,c(1,3)]
merged.table <- rbind(head(merged.table,10),tail(merged.table,10))
colnames(merged.table.zero)[2] <- paste0("price_percentile_0")
####################
# Long operation!
####################
# Divide the subtraining set into 19 log(price) quantiles + 1 "free" item bin
# Totally 19 segments
percentiles <- seq(0.05, 0.99, 0.05)
merged.table <- parse_text(mini.subtrain$brand_name[mini.subtrain$price == 0])[,c(1,3)]
merged.table <- rbind(head(merged.table,10),tail(merged.table,10))
colnames(merged.table)[2] <- paste0("price_percentile_0")
mini.subtrain.nonzero <- mini.subtrain[mini.subtrain$price != 0,]
for(i in seq_along(percentiles)){
# Perform text frequency mining within the first segment and hold the results
text <- mini.subtrain.nonzero$brand_name[log(mini.subtrain.nonzero$price) >= quantile(log(mini.subtrain.nonzero$price),percentiles[i])]
sorted.table <- parse_text(text)
sorted.table <- sorted.table[,c(1,3)]
colnames(sorted.table)[2] <- paste0("price_percentile_%",percentiles[i]*100)
sorted.table <- rbind(head(sorted.table,10),tail(sorted.table,10))
merged.table <- merge(merged.table,sorted.table, by = "Word", all = TRUE)
# continue until all price segments are finished
}
merged.table <- merged.table[!is.na(merged.table$Word),]
row.names(merged.table) = merged.table$Word
View(merged.table)
View(merged.table)
View(merged.table)
####################
# Long operation!
####################
# Divide the subtraining set into 19 log(price) quantiles + 1 "free" item bin
# Totally 19 segments
percentiles <- seq(0.05, 0.99, 0.05)
merged.table <- parse_text(mini.subtrain$brand_name[mini.subtrain$price == 0])[,c(1,3)]
colnames(merged.table)[2] <- paste0("price_percentile_0")
merged.table <- rbind(head(merged.table,10),tail(merged.table,10))
mini.subtrain.nonzero <- mini.subtrain[mini.subtrain$price != 0,]
for(i in seq_along(percentiles)){
# Perform text frequency mining within the first segment and hold the results
text <- mini.subtrain.nonzero$brand_name[log(mini.subtrain.nonzero$price) >= quantile(log(mini.subtrain.nonzero$price),percentiles[i])]
sorted.table <- parse_text(text)
sorted.table <- sorted.table[,c(1,3)]
colnames(sorted.table)[2] <- paste0("price_percentile_%",percentiles[i]*100)
sorted.table <- rbind(head(sorted.table,10),tail(sorted.table,10))
merged.table <- merge(merged.table,sorted.table, by = "Word", all = TRUE)
# continue until all price segments are finished
}
merged.table <- merged.table[!is.na(merged.table$Word),]
row.names(merged.table) = merged.table$Word
View(merged.table)
merged.table <- unique.data.frame(merged.table)
View(merged.table)
row.names(merged.table) = merged.table$Word
merged.table <- dplyr::select(merged.table, -Word)
merged.table <- as.matrix(merged.table)
#Replace NA's with zero
for (i in 1:20){merged.table[is.na(merged.table[,i]),i] <- 0}
#Save for future use
saveRDS(merged.table,"merged_table.rds")
merged.table <- readRDS("merged_table.rds")
pheatmap(t.merged.table, cluster_rows = FALSE)
# easy load
merged.table <- readRDS("merged_table.rds")
pheatmap(t(merged.table), cluster_rows = FALSE)
####################
# Long operation!
####################
# Divide the subtraining set into 19 log(price) quantiles + 1 "free" item bin
# Totally 19 segments
percentiles <- seq(0.05, 0.99, 0.05)
merged.table <- parse_text(mini.subtrain$brand_name[mini.subtrain$price == 0])[,c(1,3)]
colnames(merged.table)[2] <- paste0("price_percentile_0")
merged.table <- head(merged.table,50)
mini.subtrain.nonzero <- mini.subtrain[mini.subtrain$price != 0,]
for(i in seq_along(percentiles)){
# Perform text frequency mining within the first segment and hold the results
text <- mini.subtrain.nonzero$brand_name[log(mini.subtrain.nonzero$price) >= quantile(log(mini.subtrain.nonzero$price),percentiles[i])]
sorted.table <- parse_text(text)
sorted.table <- sorted.table[,c(1,3)]
colnames(sorted.table)[2] <- paste0("price_percentile_%",percentiles[i]*100)
sorted.table <- head(sorted.table,50)
merged.table <- merge(merged.table,sorted.table, by = "Word", all = TRUE)
# continue until all price segments are finished
}
merged.table <- merged.table[!is.na(merged.table$Word),]
merged.table <- unique.data.frame(merged.table)
row.names(merged.table) = merged.table$Word
merged.table <- dplyr::select(merged.table, -Word)
merged.table <- as.matrix(merged.table)
#Replace NA's with zero
for (i in 1:20){merged.table[is.na(merged.table[,i]),i] <- 0}
#Save for future use
saveRDS(merged.table,"merged_table.rds")
# easy load
merged.table <- readRDS("merged_table.rds")
pheatmap(t(merged.table), cluster_rows = FALSE)
# easy load
merged.table <- readRDS("merged_table.rds")
pheatmap(t(merged.table), cluster_rows = FALSE, scale = "row")
# easy load
merged.table <- readRDS("merged_table.rds")
pheatmap(t(merged.table), cluster_rows = FALSE, scale = "column")
# easy load
merged.table <- readRDS("merged_table.rds")
pheatmap(t(merged.table), cluster_rows = T, scale = "column")
# easy load
merged.table <- readRDS("merged_table.rds")
pheatmap(t(merged.table), cluster_rows = T, scale = "row")
# easy load
merged.table <- readRDS("merged_table.rds")
pheatmap(t(merged.table), cluster_rows = F, scale = "row")
View(merged.table)
word.feature.engineer <- function(text.vector,pattern){
#returns a vector that gives the counts of given pattern in each of the element of the text vector
counts <- 0
for(i in seq_along(text.vector)){
counts[i] <- str_count(text.vector[i],pattern)
}
return(counts)
}
victoria.test <- word.feature.engineer(mini.subtrain$brand_name,"victoria")
victoria.test[1:100]
mini.subtrain$brand_name[1:100]
word.feature.engineer <- function(text.vector,pattern){
#returns a vector that gives the counts of given pattern in each of the element of the text vector
text.vector <- tolower(text.vector)
counts <- 0
for(i in seq_along(text.vector)){
counts[i] <- str_count(text.vector[i],pattern)
}
counts[is.na(counts)] <- 0
return(counts)
}
victoria.test <- word.feature.engineer(mini.subtrain$brand_name,"victoria")
victoria.test[1:100]
plot(y =log(mini.subtrain$price+1),x = victoria.test,pch = 19, col = "navy" , cex = 0.4)
boxplot(y =log(mini.subtrain$price+1),x = factor(victoria.test),pch = 19, fill = "navy" , cex = 0.4)
boxplot(y =log(mini.subtrain$price+1),x = victoria.test,pch = 19, fill = "navy" , cex = 0.4)
victoria.test <- word.feature.engineer(mini.subtrain$brand_name,"victoria")
secret.test <- word.feature.engineer(mini.subtrain$brand_name,"secret")
cor(victoria.test,secret.test)
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(victoria.test)))+
geom_boxplot()
pink.test <- word.feature.engineer(mini.subtrain$brand_name,"pink")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(pink.test)))+
geom_boxplot(fill = c("navy","red"))
appl.test <- word.feature.engineer(mini.subtrain$brand_name,"appl")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(pink.test)))+
geom_boxplot(fill = c("navy","red"))
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(appl.test)))+
geom_boxplot(fill = c("navy","red"))
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(appl.test)))+
geom_boxplot(fill = c("navy","red"))+
geom_jitter(fill = c("navy","red"), alpha = 0.4)
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(appl.test)))+
geom_boxplot(fill = c("navy","red"))+
geom_jitter(fill = c("lightgreen"), alpha = 0.4)
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(appl.test)))+
geom_boxplot(fill = c("navy","red"))
michael.test <- word.feature.engineer(mini.subtrain$brand_name,"michael")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(michael.test)))+
geom_boxplot(fill = c("navy","red"))
mini.subtrain$michael.brand <- word.feature.engineer(mini.subtrain$brand_name,"michael")
subtrain$michael.brand <- word.feature.engineer(subtrain$brand_name,"michael")
pattern = "michael"
x = mini.subtrain$brand_name[1]
grepl(pattern,x)
mini.subtrain$brand_name[1]
text.vector <- mini.subtrain$brand_name
text.vector <- tolower(text.vector)
binary.vector <- sapply(text.vector,function(x){
return(ifelse(grepl(pattern,x),1,0))
})
sum(binary.vector)
sum(is.na(binary.vector))
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(binary.vector)))+
geom_boxplot(fill = c("navy","red"))
# Write a function to streamline feature engineering as binary variable
word.feature.engineer.binary <- function(text.vector,pattern){
#returns a vector that checks a given pattern in each of the element of the text vector
text.vector <- tolower(text.vector)
binary.vector <- sapply(text.vector,function(x){
return(ifelse(grepl(pattern,x),1,0))
})
return(binary.vector)
}
# Long operation!
mini.subtrain$michael.brand <- word.feature.engineer.binary(mini.subtrain$brand_name,"michael")
subtrain$michael.brand <- word.feature.engineer.binary(subtrain$brand_name,"michael")
validation$michael.brand <- word.feature.engineer.binary(validation$brand_name,"michael")
test$michael.brand <- word.feature.engineer.binary(test$brand_name,"michael")
saveRDS(mini.subtrain,"mini_subtrain.rds")
saveRDS(subtrain,"subtrain.rds")
saveRDS(validation,"validation.rds")
saveRDS(test,"test.rds")
####################
# Long operation!
####################
# Divide the subtraining set into 19 log(price) quantiles + 1 "free" item bin
# Totally 19 segments
percentiles <- seq(0.05, 0.99, 0.05)
merged.table <- parse_text(mini.subtrain$category_name[mini.subtrain$price == 0])[,c(1,3)]
colnames(merged.table)[2] <- paste0("price_percentile_0")
merged.table <- head(merged.table,50)
mini.subtrain.nonzero <- mini.subtrain[mini.subtrain$price != 0,]
for(i in seq_along(percentiles)){
# Perform text frequency mining within the first segment and hold the results
text <- mini.subtrain.nonzero$category_name[log(mini.subtrain.nonzero$price) >= quantile(log(mini.subtrain.nonzero$price),percentiles[i])]
sorted.table <- parse_text(text)
sorted.table <- sorted.table[,c(1,3)]
colnames(sorted.table)[2] <- paste0("price_percentile_%",percentiles[i]*100)
sorted.table <- head(sorted.table,50)
merged.table <- merge(merged.table,sorted.table, by = "Word", all = TRUE)
# continue until all price segments are finished
}
merged.table <- merged.table[!is.na(merged.table$Word),]
merged.table <- unique.data.frame(merged.table)
row.names(merged.table) = merged.table$Word
merged.table <- dplyr::select(merged.table, -Word)
merged.table <- as.matrix(merged.table)
#Replace NA's with zero
for (i in 1:20){merged.table[is.na(merged.table[,i]),i] <- 0}
#Save for future use
saveRDS(merged.table,"merged_table.rds")
# easy load
merged.table <- readRDS("merged_table.rds")
pheatmap(t(merged.table), cluster_rows = F, scale = "row")
####################
# Long operation!
####################
# Divide the subtraining set into 19 log(price) quantiles + 1 "free" item bin
# Totally 19 segments
percentiles <- seq(0.05, 0.99, 0.05)
merged.table <- parse_text(mini.subtrain$category_name[mini.subtrain$price == 0])[,c(1,3)]
colnames(merged.table)[2] <- paste0("price_percentile_0")
merged.table <- rbind(head(merged.table,10),tail(merged.table,10))
mini.subtrain.nonzero <- mini.subtrain[mini.subtrain$price != 0,]
for(i in seq_along(percentiles)){
# Perform text frequency mining within the first segment and hold the results
text <- mini.subtrain.nonzero$category_name[log(mini.subtrain.nonzero$price) >= quantile(log(mini.subtrain.nonzero$price),percentiles[i])]
sorted.table <- parse_text(text)
sorted.table <- sorted.table[,c(1,3)]
colnames(sorted.table)[2] <- paste0("price_percentile_%",percentiles[i]*100)
sorted.table <- rbind(head(sorted.table,10),tail(sorted.table,10))
merged.table <- merge(merged.table,sorted.table, by = "Word", all = TRUE)
# continue until all price segments are finished
}
merged.table <- merged.table[!is.na(merged.table$Word),]
merged.table <- unique.data.frame(merged.table)
row.names(merged.table) = merged.table$Word
merged.table <- dplyr::select(merged.table, -Word)
merged.table <- as.matrix(merged.table)
#Replace NA's with zero
for (i in 1:20){merged.table[is.na(merged.table[,i]),i] <- 0}
#Save for future use
saveRDS(merged.table,"merged_table.rds")
# easy load
merged.table <- readRDS("merged_table.rds")
pheatmap(t(merged.table), cluster_rows = FALSE, scale = "row")
####################
# Long operation!
####################
# Divide the subtraining set into 19 log(price) quantiles + 1 "free" item bin
# Totally 19 segments
percentiles <- seq(0.05, 0.99, 0.05)
merged.table <- parse_text(mini.subtrain$name[mini.subtrain$price == 0])[,c(1,3)]
colnames(merged.table)[2] <- paste0("price_percentile_0")
merged.table <- rbind(head(merged.table,10),tail(merged.table,10))
mini.subtrain.nonzero <- mini.subtrain[mini.subtrain$price != 0,]
for(i in seq_along(percentiles)){
# Perform text frequency mining within the first segment and hold the results
text <- mini.subtrain.nonzero$name[log(mini.subtrain.nonzero$price) >= quantile(log(mini.subtrain.nonzero$price),percentiles[i])]
sorted.table <- parse_text(text)
sorted.table <- sorted.table[,c(1,3)]
colnames(sorted.table)[2] <- paste0("price_percentile_%",percentiles[i]*100)
sorted.table <- rbind(head(sorted.table,10),tail(sorted.table,10))
merged.table <- merge(merged.table,sorted.table, by = "Word", all = TRUE)
# continue until all price segments are finished
}
merged.table <- merged.table[!is.na(merged.table$Word),]
merged.table <- unique.data.frame(merged.table)
row.names(merged.table) = merged.table$Word
merged.table <- dplyr::select(merged.table, -Word)
merged.table <- as.matrix(merged.table)
#Replace NA's with zero
for (i in 1:20){merged.table[is.na(merged.table[,i]),i] <- 0}
#Save for future use
saveRDS(merged.table,"merged_table.rds")
# easy load
merged.table <- readRDS("merged_table.rds")
pheatmap(t(merged.table), cluster_rows = FALSE, scale = "row")
pink.test <- word.feature.engineer.binary(mini.subtrain$name,"pink")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(pink.test)))+
geom_boxplot(fill = c("navy","red"))
size.test <- word.feature.engineer.binary(mini.subtrain$name,"pink")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(size.test)))+
geom_boxplot(fill = c("navy","red"))
jordan.test <- word.feature.engineer.binary(mini.subtrain$name,"jordan")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(jordan.test)))+
geom_boxplot(fill = c("navy","red"))
size.test <- word.feature.engineer.binary(mini.subtrain$name,"size")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(size.test)))+
geom_boxplot(fill = c("navy","red"))
shirt.test <- word.feature.engineer.binary(mini.subtrain$name,"shirt")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(shirt.test)))+
geom_boxplot(fill = c("navy","red"))
michael.test <- word.feature.engineer.binary(mini.subtrain$name,"michael")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(michael.test)))+
geom_boxplot(fill = c("navy","red"))
cor(michael.test,michael.brand)
cor(michael.test,mini.subtrain$michael.brand)
iphon.test <- word.feature.engineer.binary(mini.subtrain$name,"iphon")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(iphon.test)))+
geom_boxplot(fill = c("navy","red"))
table(iphon.test)
table(jordan.test)
bundl.test <- word.feature.engineer.binary(mini.subtrain$name,"bundl")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(bundl.test)))+
geom_boxplot(fill = c("navy","red"))
table(bundl.test)
# Long operation!
mini.subtrain$jordan.name <- word.feature.engineer.binary(mini.subtrain$name,"jordan")
subtrain$jordan.name <- word.feature.engineer.binary(subtrain$name,"jordan")
validation$jordan.name <- word.feature.engineer.binary(validation$name,"jordan")
test$jordan.name <- word.feature.engineer.binary(test$brand,"jordan")
mini.subtrain$iphon.name <- word.feature.engineer.binary(mini.subtrain$name,"iphon")
subtrain$iphon.name <- word.feature.engineer.binary(subtrain$name,"iphon")
validation$iphon.name <- word.feature.engineer.binary(validation$name,"iphon")
test$iphon.name <- word.feature.engineer.binary(test$brand,"iphon")
mini.subtrain$bundl.name <- word.feature.engineer.binary(mini.subtrain$name,"bundl")
subtrain$bundl.name <- word.feature.engineer.binary(subtrain$name,"bundl")
validation$bundl.name <- word.feature.engineer.binary(validation$name,"bundl")
test$bundl.name <- word.feature.engineer.binary(test$brand,"bundl")
#At this point it is necessary to save engineered data sets again for future easy loading:
saveRDS(mini.subtrain,"mini_subtrain.rds")
saveRDS(subtrain,"subtrain.rds")
saveRDS(validation,"validation.rds")
saveRDS(test,"test.rds")
placeholder.test <- word.feature.engineer.binary(mini.subtrain$name,"\\[rm]")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(placeholder.test)))+
geom_boxplot(fill = c("navy","red"))
placeholder.test <- word.feature.engineer.binary(mini.subtrain$item_description,"\\[rm]")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(placeholder.test)))+
geom_boxplot(fill = c("navy","red"))
placeholder.test <- word.feature.engineer(mini.subtrain$name,"\\[rm]")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(placeholder.test)))+
geom_boxplot(fill = c("navy","red"))
placeholder.test <- word.feature.engineer(mini.subtrain$name,"\\[rm]")
ggplot(mini.subtrain,aes(y = log(price +1), x = factor(placeholder.test)))+
geom_boxplot(fill = c("navy","red","lightgreen"))
capital.letter.counter <- function(text.vector){
# Return the occurance of capital letters in the given text vector
capital.letter.count <- sapply(text.vector,function(x){
return(nchar(grep("[A-Z]",x)))})
}
capital.letter.test <- capital.letter.counter(mini.subtrain$item_description)
capital.letter.test[1:5]
text.vector = mini.subtrain$item_description[1]
x = text.vector
grep("[A-Z]",x)
x
grepRaw("[A-Z]",x)
grep("[A-Z]",x, value = T)
str_extract(x,"[A-Z]")
str_extract(x,"*[A-Z]")
str_extract(x,"[*A-Z]")
str_extract_all(x,"[A-Z]")
unlist(str_extract_all(x,"[A-Z]"))
length(unlist(str_extract_all(x,"[A-Z]")))
capital.letter.counter <- function(text.vector){
# Return the occurance of capital letters in the given text vector
capital.letter.count <- sapply(text.vector,function(x){
return(length(unlist(str_extract_all(x,"[A-Z]"))))})
}
capital.letter.test <- capital.letter.counter(mini.subtrain$item_description)
plot(y =log(mini.subtrain$price) x = capital.letter.test,pch = 19, col = "navy", cex = 0.2)
plot(y =log(mini.subtrain$price), x = capital.letter.test,pch = 19, col = "navy", cex = 0.2)
plot(y =log(mini.subtrain$price), x = log(capital.letter.test),pch = 19, col = "navy", cex = 0.2)
capital.letter.test <- capital.letter.counter(mini.subtrain$name)
plot(y =log(mini.subtrain$price), x = log(capital.letter.test),pch = 19, col = "navy", cex = 0.2)
capital.letter.test <- capital.letter.counter(mini.subtrain$brand_name)
plot(y =log(mini.subtrain$price), x = log(capital.letter.test),pch = 19, col = "navy", cex = 0.2)
capital.letter.test <- capital.letter.counter(mini.subtrain$category_name)
plot(y =log(mini.subtrain$price), x = log(capital.letter.test),pch = 19, col = "navy", cex = 0.2)
capital.letter.test <- capital.letter.counter(mini.subtrain$brand_name)
plot(y =log(mini.subtrain$price), x = log(capital.letter.test),pch = 19, col = "navy", cex = 0.2)
# Long operation!
mini.subtrain$cap.letter.brand <- capital.letter.counter(mini.subtrain$brand_name)
subtrain$cap.letter.brand <- capital.letter.counter(subtrain$brand_name)
validation$cap.letter.brand <- capital.letter.counter(valiadtion$brand_name)
validation$cap.letter.brand <- capital.letter.counter(validation$brand_name)
test$cap.letter.brand <- capital.letter.counter(test$brand_name)
#At this point it is necessary to save engineered data sets again for future easy loading:
saveRDS(mini.subtrain,"mini_subtrain.rds")
saveRDS(subtrain,"subtrain.rds")
saveRDS(validation,"validation.rds")
saveRDS(test,"test.rds")
mini.subtrain <-dplyr::select(mini.subtrain, -name, -item_description,-category_name, -brand_name)
subtrain <-dplyr::select(subtrain, -name, -item_description,-category_name, -brand_name)
validation <-dplyr::select(validation, -name, -item_description,-category_name, -brand_name)
test <-dplyr::select(test, -name, -item_description,-category_name, -brand_name)
library(corrplot)
corrplot(cor(mini.subtrain), method = c("shade"), bg = "gray", addgrid.col = "gray")
#At this point it is necessary to save engineered data sets again for future easy loading:
saveRDS(mini.subtrain,"mini_subtrain_locked.rds")
saveRDS(subtrain,"subtrain_locked.rds")
saveRDS(validation,"validation_locked.rds")
saveRDS(test,"test_locked.rds")
# Find the 10 most frequent terms: term_count
term_count <- freq_terms(new_text,4)
library(qdap)
# Print new_text to the console
new_text <- "Text mining usually involves the process of structuring the input text. The overarching goal is, essentially, to turn text into data for analysis, via application of natural language processing (NLP) and analytical methods."
# Find the 10 most frequent terms: term_count
term_count <- freq_terms(new_text,4)
# Plot term_count
plot(term_count)
tweets <- read.csv("https://assets.datacamp.com/production/course_935/datasets/coffee.csv", stringsAsFactors = FALSE)
str(tweets)
View(tweets)
nrow(tweets)
# Isolate text from tweets: coffee_tweets
coffee_tweets <- tweets$text
# Load tm
library(tm)
# Make a vector source: coffee_source
coffee_source <- VectorSource(coffee_tweets)
## coffee_source is already in your workspace
# Make a volatile corpus: coffee_corpus
coffee_corpus <- VCorpus(coffee_source)
# Print out coffee_corpus
coffee_corpus
# Print data on the 15th tweet in coffee_corpus
coffee_corpus[[15]]
# Print the content of the 15th tweet in coffee_corpus
coffee_corpus[[15]][1]
# Create the object: text
text <- "<b>She</b> woke up at       6 A.M. It\'s so early!  She was only 10% awake and began drinking coffee in front of her computer."
# All lowercase
tolower(text)
# Remove punctuation
removePunctuation(text)
# Remove numbers
removeNumbers(text)
# Remove whitespace
stripWhitespace(text)
stemDocument(c("computational", "computers", "computation"))
# Create complicate
complicate <- c("complicated", "complication","complicatedly" )
# Perform word stemming: stem_doc
stem_doc <- stemDocument(complicate)
# Create the completion dictionary: comp_dict
comp_dict <- "complicate"
# Perform stem completion: complete_text
complete_text <- stemCompletion(stem_doc,comp_dict)
# Print complete_text
print(complete_text)
shiny::runApp('Desktop/2016/Data_science/companion')
events.list <- unique(fromJSON(paste0('https://api.fda.gov/drug/event.json?search=receivedate:[',start.date,'+TO+',end.date,']+AND+patient.drug.openfda.brand_name.exact:(%22',drug,'%22)&count=patient.reaction.reactionmeddrapt.exact'))$results$term)
message(        events.list <- unique(fromJSON(paste0('https://api.fda.gov/drug/event.json?search=receivedate:[',start.date,'+TO+',end.date,']+AND+patient.drug.openfda.brand_name.exact:(%22',drug,'%22)&count=patient.reaction.reactionmeddrapt.exact'))$results$term)
)
drug.list
shiny::runApp('Desktop/2016/Data_science/companion')
runApp('Desktop/2016/Data_science/companion')
print(p)
drug.FLAG
input$device.checkbox
!is.null(drug.device.data)
input$device.checkbox & !is.null(drug.device.data)
p
runApp('Desktop/2016/Data_science/companion')
runApp('Desktop/2016/Data_science/companion')
runApp('Desktop/2016/Data_science/companion')
runApp('Desktop/2016/Data_science/companion')
runApp('Desktop/2016/Data_science/companion')
runApp('Desktop/2016/Data_science/companion')
View(states_map)
setwd("~/Desktop/2016/Data_science/companion")
runApp()
runApp()
p
runApp()
Q
runApp()
runApp()
runApp()
runApp()
runApp()
drug.FLAG
ggplotly(pl)
ggplotly(pl)
ggplotly(pl)
ggplotly(pl)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
